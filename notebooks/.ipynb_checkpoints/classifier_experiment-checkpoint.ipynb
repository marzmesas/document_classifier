{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels_and_text(df):\n",
    "    labels = [int(i[0]) for i in df['5485']]\n",
    "    df['labels'] = labels\n",
    "    df = df.rename({'5485': 'doc_text'}, axis=1)\n",
    "    df['doc_text'] = df['doc_text'].str[1:]\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    df = preprocess_labels_and_text(df)\n",
    "    X = df['doc_text']\n",
    "    y = df['labels']\n",
    "    return X, y, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TF-IDF + CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_features_tfidf(X_train, y_train):\n",
    "    # Apply TF-IDF with a HIGH max_features (e.g., 10,000)\n",
    "    high_max_features = 10000\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=high_max_features)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # Train a Random Forest Classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Get Feature Importances\n",
    "    feature_importances = rf.feature_importances_\n",
    "\n",
    "    # Determine Optimal max_features (Keeping Top 90% of Importance)\n",
    "    sorted_indices = np.argsort(feature_importances)[::-1]  # Sort features by importance (descending)\n",
    "    cumulative_importance = np.cumsum(feature_importances[sorted_indices])  # Cumulative importance\n",
    "    best_max_features = np.argmax(cumulative_importance >= 0.90)  # Find cutoff for 90% importance\n",
    "    return best_max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_test_pred, average='weighted', zero_division=1),\n",
    "        \"Precision\": precision_score(y_test, y_test_pred, average='weighted', zero_division=1),\n",
    "        \"Recall\": recall_score(y_test, y_test_pred, average='weighted', zero_division=1)\n",
    "    }\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_test_pred, labels=model.classes_)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    # disp.plot(cmap='Blues')\n",
    "    # plt.title(f\"Confusion matrix for {type(model).__name__}\")\n",
    "    # plt.show()\n",
    "\n",
    "    # print(f\"\\nClassification report for {type(model).__name__}:\\n\")\n",
    "    # print(classification_report(y_test, y_test_pred, zero_division=1))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test, models, names):\n",
    "    results = []\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"Training and evaluating: {name}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        metrics = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "        results.append({\"Classifier\": name, **metrics})\n",
    "        # print(f\"Results for {name}: {metrics}\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(results):\n",
    "    results.sort_values(by=\"Accuracy\", ascending=False, inplace=True)\n",
    "    plt.bar(results[\"Classifier\"], results[\"Accuracy\"])\n",
    "    plt.title(\"Model comparison\")\n",
    "    plt.xlabel(\"Models\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run classification comparison with Lazypredict\n",
    "# clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "# models, predictions = clf.fit(X_train_tfidf.toarray(), X_test_tfidf.toarray(), y_train, y_test)\n",
    "\n",
    "# # Display model performance comparison\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset and preprocess it\n",
    "path_csv = '../data/file.txt'\n",
    "df = pd.read_csv(path_csv)\n",
    "X, y, df = prepare_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' champion products ch approves stock split champion products inc said its board of directors approved a two for one stock split of its common shares for shareholders of record as of april the company also said its board voted to recommend to shareholders at the annual meeting april an increase in the authorized capital stock from five mln to mln shares reuter '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.doc_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Best max_features: 1175\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get best max_features value   \n",
    "best_max_features = get_max_features_tfidf(X_train, y_train)\n",
    "\n",
    "# Use the best max_features value for final TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=best_max_features)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Selected Best max_features: {best_max_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating: Logistic Regression\n",
      "Training and evaluating: KNN Classifier\n",
      "Training and evaluating: Decision Tree\n",
      "Training and evaluating: Linear SVM\n",
      "Training and evaluating: Random Forest\n",
      "Training and evaluating: SGD Classifier\n",
      "Training and evaluating: Ridge Classifier\n",
      "Training and evaluating: XGBoost\n",
      "Training and evaluating: AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# Model Zoo\n",
    "names = [\n",
    "    \"Logistic Regression\",\n",
    "    \"KNN Classifier\",\n",
    "    \"Decision Tree\",\n",
    "    \"Linear SVM\",\n",
    "    \"Random Forest\",\n",
    "    \"SGD Classifier\",\n",
    "    \"Ridge Classifier\",\n",
    "    \"XGBoost\",\n",
    "    \"AdaBoost\",\n",
    "]\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    KNeighborsClassifier(n_neighbors=149, n_jobs=-1),\n",
    "    DecisionTreeClassifier(),\n",
    "    SVC(kernel='linear'),\n",
    "    RandomForestClassifier(n_estimators=100, class_weight='balanced'),\n",
    "    SGDClassifier(loss='hinge'),\n",
    "    RidgeClassifier(),\n",
    "    XGBClassifier(),\n",
    "    AdaBoostClassifier()\n",
    "]\n",
    "\n",
    "# Training and evaluation\n",
    "results = train_and_evaluate_models(X_train_tfidf, y_train, X_test_tfidf, y_test, models, names)\n",
    "\n",
    "# Result plotting\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Accuracy  F1 Score  Precision  Recall\n",
       "0  Logistic Regression      0.95      0.95       0.96    0.95\n",
       "1       KNN Classifier      0.91      0.90       0.91    0.91\n",
       "2        Decision Tree      0.89      0.89       0.89    0.89\n",
       "3           Linear SVM      0.97      0.97       0.97    0.97\n",
       "4        Random Forest      0.95      0.95       0.95    0.95\n",
       "5       SGD Classifier      0.97      0.97       0.97    0.97\n",
       "6     Ridge Classifier      0.97      0.97       0.97    0.97\n",
       "7              XGBoost      0.95      0.95       0.95    0.95\n",
       "8             AdaBoost      0.75      0.73       0.84    0.75"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BERT + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel, AutoTokenizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch.nn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
